# Open X-Embodiment: 机器人学习数据集和RT-X模型

![iShot_2025-04-02_15.04.19](https://raw.githubusercontent.com/1910853272/image/master/img/202504021504265.png)

发布Open X-Embodiment (OXE) 数据集，包含21个机构的22种机器人数据，527个技能（160266个任务），在9种机械臂上训练RT-1和RT-2模型，升级为RT-X，展现出更强的泛化能力和新技能。

# Open X-Embodiment 数据集

整合了来自 34 个机器人实验室 的 60 个现有数据集。采用 RLDS 数据格式，统一存储为 TFRecord 文件，支持：不同机器人的动作空间（如关节控制、末端执行器控制）、多种输入模态（RGB 相机、深度相机、点云等）、高效的并行数据加载（兼容主流深度学习框架）。

![iShot_2025-04-02_15.31.11](https://raw.githubusercontent.com/1910853272/image/master/img/202504021531824.png)

a.**机器人类型分布**

b.**场景多样性**

c.**轨迹数量**

d.**常见数据集技能**

e.**常见数据集物体**

#  RT-X 模型设计

![iShot_2025-04-02_15.51.35](https://raw.githubusercontent.com/1910853272/image/master/img/202504021553366.png)

## 1.数据格式统一

**观测输入**：

- 模型接收历史图像序列和语言指令。
- 从每个数据集中选择一个标准视角的RGB图像，统一分辨率（如调整至固定尺寸）。

**动作输出**：

- 预测7维末端执行器动作向量（x, y, z, roll, pitch, yaw, 夹爪开合度或其变化率）。
- 对原始动作进行归一化和离散化，便于模型输出。

**灵活性保留**：

- 相机位姿和控制坐标系未强制对齐，允许不同机器人对相同动作向量产生不同运动

## 2.RT-1-X：专用机器人控制优化

**输入**：15帧历史图像（通过ImageNet预训练的EfficientNet 提取特征）、语言指令（编码为USE嵌入向量）

**特征融合**：使用FiLM层交织视觉与语言特征，生成81个多模态token。

**动作预测**：通过纯解码器Transformer输出离散化动作（8维，含1维终止标志+7维运动控制）。

## 3.RT-2-X：基于视觉-语言模型（VLM）

基于大规模视觉-语言模型（VLM）微调，将动作预测转化为文本token生成任务

**视觉部分**：ViT（Vision Transformer） 处理图像。

**语言部分**：UL2 编码文本指令。

**预训练数据：**WebLI 

# 实验结果

## 1.跨具身训练能否实现正向迁移

**小规模数据集评估**：测试RT-1-X在数据稀缺场景的表现。RT-1-X在5个数据集中有4个显著优于Original Method，证明跨数据训练弥补了数据不足。

![iShot_2025-04-02_17.24.10](https://raw.githubusercontent.com/1910853272/image/master/img/202504021724727.png)

**大规模数据集评估**：对比RT-1-X和RT-2-X在数据丰富场景的性能。RT-1-X未超越单数据集训练的RT-1（可能因模型容量不足）。RT-2-X（55B参数）则全面超越Original Method和RT-1，表明高容量模型能进一步利用跨数据信息。

![iShot_2025-04-02_17.28.57](https://raw.githubusercontent.com/1910853272/image/master/img/202504021729607.png)

## 2.跨具身训练能否提升泛化能力

**未见过的物体、背景和环境**：（表II，第1行和第2行，最后一列）RT-2和RT-2-X的表现大致相当。

**新兴技能评估**：让Google Robot执行WidowX数据集中存在的技能（但Google Robot原数据未包含），RT-2-X在新兴任务上的成功率是RT-2的3倍。

**去除Bridge数据集**：（表II第3行），WidowX数据中转移的知识可能确实是RT-2-X在Google Robot上能够执行更多任务的原因

![iShot_2025-04-02_19.32.19](https://raw.githubusercontent.com/1910853272/image/master/img/202504021932010.png)

## 3.模型设计如何影响性能

消融实验衡量不同设计对RT-2-X模型泛化能力的影响

**历史图像帧**：加入时序图像显著提升泛化能力（第4 vs 第5行）。

**网络预训练**：基于WebLI的预训练对高性能至关重要（第4 vs 第6行）。

**模型容量**：55B参数的RT-2-X比5B模型在新兴任务上表现更优（第2 vs 第4行），说明大模型能更好地迁移跨机器人知识。